# -*- coding: utf-8 -*-
"""Ejemplo_IMC3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Lz4eBMdxbIULGt2jfIVylWRSkc_UIHVc
"""

#from google.colab import files
#files.upload()

from sklearn import preprocessing as pp
from sklearn.linear_model import LogisticRegression
from sklearn import neighbors
import numpy as np
import pandas as pd

wine = pd.read_csv('wine.data', names=None)

#print(wine)

numPatrones = np.random.rand(len(wine)) < 0.6 #Cogemos valores menores a 0.6 y los ponemos como true
train = wine[numPatrones]
test = wine[~numPatrones]
#print(numPatrones)

print(train.shape[1])

train_inputs = train.values[:,1:13]
train_outputs = train.values[:,0]

test_inputs = test.values[:,1:13]
test_outputs = test.values[:,0]

min_max_scaler = pp.MinMaxScaler()
X_train_minmax = min_max_scaler.fit_transform(train_inputs)
#print(X_train_minmax)

X_test_minmax = min_max_scaler.fit_transform(test_inputs)
#print(X_test_minmax)

for nn in range(1,15):
    knn = neighbors.KNeighborsClassifier(n_neighbors=nn)
    knn.fit(X_train_minmax, train_outputs)
    precisionTrain = knn.score(X_train_minmax, train_outputs)
    precisionTest = knn.score(X_test_minmax, test_outputs)
    print("%d vecinos: \tCCR train = %.2f%%, \tCCR test = %.2f%%" % (nn, precisionTrain*100, precisionTest*100))

for nn in range(1,15):
    reg = 'l1'

    logreg = LogisticRegression(penalty = reg, C = 1/0.01, fit_intercept = False, solver = 'liblinear', multi_class='auto')
    logreg.fit(X_train_minmax, train_outputs)
    precisionTrain = logreg.score(X_train_minmax, train_outputs)
    precisionTest = logreg.score(X_test_minmax, test_outputs)

    print("%d vecinos: \tCCR train = %.2f%%, \tCCR test = %.2f%%" % (nn, precisionTrain*100, precisionTest*100))